================================
SYNCHRONY ANALYSIS V2
COMPLETE DEPENDENCIES & DATASET INFO
================================

Last Updated: December 2, 2025
Status: ✓ READY FOR ANALYSIS

================================
DATASET SUMMARY
================================

Total: 15 subjects, 28 subject-runs
All files verified: check_files_v2.py ✓ PASSED

ALL SUBJECTS AFNI-READY (15 subjects, 28 runs - can process immediately):
  1. AE (runs 1,2,3)
  2. AIM (runs 1,2) - Note: Same subject as "AlM" in gastric data
  3. AlS (runs 1,2)
  4. AmK (runs 1,2)
  5. AnF (runs 1,2)
  6. AzN (runs 1,2)
  7. BS (runs 1,2)
  8. DaH (runs 1,2)
  9. DoP (run 1)
  10. EdZ (run 1)
  11. ElL (runs 1,2)
  12. ErG (run 1)
  13. HaM (runs 1,2)
  14. IdS (runs 1,2)
  15. LA (runs 1,2)

Excluded: 28 subjects (no motion or gastric data)
  → See "EXCLUDED SUBJECTS" section below

================================
IMPORTANT: AIM/AlM NAMING
================================

AIM and AlM are THE SAME SUBJECT with inconsistent naming:
  - Motion files use:    AIM  (sub-AIM_dfile.r01.1D, r02.1D)
  - Gastric data uses:   AlM  (derivatives/brain_gast/AlM/)
  - AFNI preprocessing:  AIM  (BIDS_data/soroka/sub-AIM/)

Solution:
  ✓ Standardized to "AIM" in egg_brain_meta_data_v2.csv
  ✓ Created symbolic links: derivatives/brain_gast/AIM -> AlM
  ✓ Scripts work with both names transparently

================================
PYTHON PACKAGES REQUIRED
================================

Install these with pip:

pip install numpy pandas scipy nilearn nibabel matplotlib mne scikit-learn nipype

Package versions tested:
- numpy >= 1.20
- pandas >= 1.3
- scipy >= 1.7
- nilearn >= 0.8
- nibabel >= 3.2
- matplotlib >= 3.4
- mne >= 0.24
- scikit-learn >= 0.24
- nipype >= 1.7

================================
EXTERNAL SOFTWARE
================================

For voxel-based analysis (REQUIRED):
- FSL (FMRIB Software Library)
  - Needed for: MNI template (voxel_based_analysis_v2.py)
  - Set: export FSLDIR=/path/to/fsl
  - Quick setup:
      source ~/.bash_profile
    OR add to conda environment activation

For second-level analysis (OPTIONAL):
- FSL randomise tool
  - Only needed for group-level statistics

For AFNI workflow:
- AFNI (already installed if you preprocessed with AFNI)

================================
REQUIRED INPUT FILES
================================

For EACH subject and run, you need:

1. Motion parameters (.1D files) ✓ AVAILABLE
   Location: BIDS_data/sub_motion_files/sub-{subject}_dfile.r0{run}.1D
   Format: 6 columns (trans_x, trans_y, trans_z, rot_x, rot_y, rot_z)
   Example: BIDS_data/sub_motion_files/sub-AE_dfile.r01.1D

2. Gastric signal (.npy files) ✓ AVAILABLE
   Location: derivatives/brain_gast/{subject}/{subject}{run}/gast_data_{subject}_run{run}strict.npy
   Format: NumPy array, 1D, sampled at 10 Hz
   Example: derivatives/brain_gast/AE/AE1/gast_data_AE_run1strict.npy

3. Gastric frequency (.npy files) ✓ AVAILABLE
   Location: derivatives/brain_gast/{subject}/{subject}{run}/max_freq{subject}_run{run}strict.npy
   Format: NumPy array with single float value (peak frequency)
   Example: derivatives/brain_gast/AE/AE1/max_freqAE_run1strict.npy

4. Metadata CSV ✓ AVAILABLE
   Location: dataframes/egg_brain_meta_data_v2.csv
   Required columns: subject, run
   Note: 15 subjects, 28 runs (AIM/AlM resolved to AIM)

================================
AFNI PREPROCESSED DATA (ALL 15 SUBJECTS)
================================

Location: BIDS_data/soroka/sub-{subject}/anat_func/PreprocessedData/
Available for: ALL 15 subjects (AE, AIM, AlS, AmK, AnF, AzN, BS, DaH, DoP, EdZ, ElL, ErG, HaM, IdS, LA)

For each subject/run, use:
  python synchrony_analysis/prepare_afni_data.py {subject} {run}

This creates the brain signal files needed for synchrony analysis.

Note: AIM gastric data is in derivatives/brain_gast/AlM/ (symbolic link created)

================================
FILES CREATED BY PREPARE_AFNI_DATA
================================

These files are created per subject/run:

1. Filtered brain signal (.npz files)
   Location: derivatives/brain_gast/{subject}/{subject}{run}/func_filtered_{subject}_run{run}strict.npz
   Format: NumPy compressed archive with 'brain_signal' array

2. Brain mask (.npz files)
   Location: derivatives/brain_gast/mask_{subject}_run{run}strict.npz
   Format: NumPy compressed archive with 'mask' array (boolean)

3. Preprocessed fMRI (.nii.gz files)
   Location: derivatives/brain_gast/{subject}/{subject}{run}/{subject}_task-rest_run-0{run}_space-MNI_desc-preproc_bold_strict.nii.gz
   Format: NIfTI file in MNI space

================================
UTILITY FILES
================================

These are already in the code/ folder:

1. code/utils/gastric_utils.py ✓ EXISTS
   - Contains: to_phase_resampled(), plot_example_synchrony()

2. code/config.py ✓ EXISTS
   - Contains: main_project_path, clean_level, sample_rate_fmri, etc.

================================
OUTPUT DIRECTORIES
================================

Create these if they don't exist:

mkdir -p dataframes
mkdir -p plots/brain_gast
mkdir -p derivatives/brain_gast/fsl_randomize

================================
WORKFLOW STEPS
================================

Step 1: Check files ✓ READY
  python synchrony_analysis/check_files_v2.py

Step 2: Gastric-motion analysis (optional) ✓ READY
  python synchrony_analysis/egg_confounds_synchrony_v2.py

Step 3: Prepare AFNI data (for all 15 subjects) ✓ READY
  python synchrony_analysis/prepare_afni_data.py {subject} {run}

Step 4: Signal slicing ⚠ NEEDS STEP 3 FIRST
  python synchrony_analysis/signal_slicing_v2.py {subject} {run}

Step 5: Voxel-based analysis ⚠ NEEDS STEP 4 FIRST
  python synchrony_analysis/voxel_based_analysis_v2.py {subject} {run}

Step 6: Second-level analysis ⚠ NEEDS ALL SUBJECTS PROCESSED
  python synchrony_analysis/voxel_based_second_level_v2.py

================================
QUICK VERIFICATION
================================

Run this to verify everything is ready:

cd code
python synchrony_analysis/check_files_v2.py

Expected output: "Done files pre check."

================================
EXCLUDED SUBJECTS (28 total)
================================

From original CSV (43 subjects), 28 subjects excluded due to missing data:

Missing gastric AND motion data:
  OE, SE, SP, OfA, SS, OzO, MaD, RoH, TaR, OrS, ShR, NH, NiC, ToL, ShL,
  NoaG, MaE, MoM, TiP, RoK, SiC, TzS, NoL, OmS, YoY, RoL, NeI, ShKh

These subjects have no files in:
  - BIDS_data/sub_motion_files/
  - derivatives/brain_gast/
  - BIDS_data/soroka/

To include any of these subjects:
  1. Acquire/locate the raw data
  2. Run preprocessing (AFNI or fMRIPrep)
  3. Process gastric data
  4. Add to egg_brain_meta_data_v2.csv

================================
EXPECTED FILE SIZES
================================

For a typical subject with 2-3 runs:
- func_filtered_*.npz: ~50-100 MB per run
- mask_*.npz: ~1-2 MB per run
- Preprocessed NIfTI: ~200-500 MB per run
- PLV output maps: ~10-20 MB per map

================================
READY TO START?
================================

Current setup with 15 subjects is verified and ready!

Process your first AFNI subject:
  cd code
  python synchrony_analysis/prepare_afni_data.py AE 1
  python synchrony_analysis/signal_slicing_v2.py AE 1
  python synchrony_analysis/voxel_based_analysis_v2.py AE 1

For complete workflow, see README_v2.md
For quick commands, see START_HERE.txt
For AFNI details, see QUICKSTART_AFNI.md

================================